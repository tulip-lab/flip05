{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP (05): Learning Theory (II)\n",
    "**(Module 04: Gaussian Process)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================\n",
    "Illustration of Gaussian process classification (GPC) on the XOR dataset\n",
    "========================================================================\n",
    "This example illustrates GPC on XOR data. Compared are a stationary, isotropic\n",
    "kernel (RBF) and a non-stationary kernel (DotProduct). On this particular\n",
    "dataset, the DotProduct kernel obtains considerably better results because the\n",
    "class-boundaries are linear and coincide with the coordinate axes. In general,\n",
    "stationary kernels often obtain better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(200, 2)\n",
    "Y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
    "\n",
    "# fit the model\n",
    "plt.figure(figsize=(10, 5))\n",
    "kernels = [1.0 * RBF(length_scale=1.0), 1.0 * DotProduct(sigma_0=1.0)**2]\n",
    "for i, kernel in enumerate(kernels):\n",
    "    clf = GaussianProcessClassifier(kernel=kernel, warm_start=True).fit(X, Y)\n",
    "\n",
    "    # plot the decision function for each datapoint on the grid\n",
    "    Z = clf.predict_proba(np.vstack((xx.ravel(), yy.ravel())).T)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    image = plt.imshow(Z, interpolation='nearest',\n",
    "                       extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                       aspect='auto', origin='lower', cmap=plt.cm.PuOr_r)\n",
    "    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
    "                           linetypes='--')\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=Y, cmap=plt.cm.Paired,\n",
    "                edgecolors=(0, 0, 0))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    plt.colorbar(image)\n",
    "    plt.title(\"%s\\n Log-Marginal-Likelihood:%.3f\"\n",
    "              % (clf.kernel_, clf.log_marginal_likelihood(clf.kernel_.theta)),\n",
    "              fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
